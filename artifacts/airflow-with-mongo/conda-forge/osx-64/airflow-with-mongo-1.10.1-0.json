{
 "about": {
  "channels": [
   "conda-forge",
   "defaults"
  ],
  "conda_build_version": "3.16.3",
  "conda_private": false,
  "conda_version": "4.5.11",
  "description": "Use airflow to author workflows as directed acyclic graphs (DAGs)\nof tasks. The airflow scheduler executes your tasks on an array of\nworkers while following the specified dependencies. Rich command\nline utilities make performing complex surgeries on DAGs a snap.\nThe rich user interface makes it easy to visualize pipelines\nrunning in production, monitor progress, and troubleshoot issues\nwhen needed.\n\nWhen workflows are defined as code, they become more maintainable,\nversionable, testable, and collaborative.\n",
  "dev_url": "https://github.com/apache/incubating-airflow",
  "doc_url": "http://pythonhosted.org/airflow/profiling.html",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "parent_recipe": {
    "name": "airflow-split",
    "path": "/Users/travis/build/conda-forge/airflow-feedstock/recipe",
    "version": "1.10.1"
   },
   "recipe-maintainers": [
    "sodre",
    "halldc"
   ]
  },
  "home": "http://airflow.apache.org",
  "identifiers": [],
  "keywords": [],
  "license": "Apache 2.0",
  "license_file": "LICENSE",
  "root_pkgs": [
   "anaconda-client 1.7.2 py36_0",
   "asn1crypto 0.24.0 py36_0",
   "beautifulsoup4 4.6.3 py36_0",
   "bzip2 1.0.6 h1de35cc_5",
   "ca-certificates 2018.03.07 0",
   "certifi 2018.10.15 py36_0",
   "cffi 1.11.5 py36h6174b99_1",
   "chardet 3.0.4 py36_1",
   "click 7.0 py36_0",
   "clyent 1.2.2 py36_1",
   "conda 4.5.11 py36_0",
   "conda-build 3.16.3 py36_0",
   "conda-env 2.6.0 1",
   "conda-forge-ci-setup 2.1.0 py36_0",
   "cryptography 2.4.1 py36ha12b0ac_0",
   "decorator 4.3.0 py36_0",
   "filelock 3.0.10 py36_0",
   "glob2 0.6 py36_1",
   "icu 58.2 h4b95b61_1",
   "idna 2.7 py36_0",
   "ipython_genutils 0.2.0 py36h241746c_0",
   "jinja2 2.10 py36_0",
   "jsonschema 2.6.0 py36hb385e00_0",
   "jupyter_core 4.4.0 py36_0",
   "libarchive 3.3.3 he8b1da1_4",
   "libcxx 4.0.1 h579ed51_0",
   "libcxxabi 4.0.1 hebd6815_0",
   "libedit 3.1.20170329 hb402a30_2",
   "libffi 3.2.1 h475c297_4",
   "libiconv 1.15 hdd342a3_7",
   "libxml2 2.9.8 hab757c2_1",
   "lz4-c 1.8.1.2 h1de35cc_0",
   "lzo 2.10 h362108e_2",
   "markupsafe 1.1.0 py36h1de35cc_0",
   "nbformat 4.4.0 py36h827af21_0",
   "ncurses 6.1 h0a44026_0",
   "openssl 1.1.1a h1de35cc_0",
   "pip 18.1 py36_0",
   "pkginfo 1.4.2 py36_1",
   "psutil 5.4.8 py36h1de35cc_0",
   "pycosat 0.6.3 py36h1de35cc_0",
   "pycparser 2.19 py36_0",
   "pyopenssl 18.0.0 py36_0",
   "pysocks 1.6.8 py36_0",
   "python 3.6.7 haf84260_0",
   "python-dateutil 2.7.5 py36_0",
   "python-libarchive-c 2.8 py36_6",
   "python.app 2 py36_9",
   "pytz 2018.7 py36_0",
   "pyyaml 3.13 py36h1de35cc_0",
   "readline 7.0 h1de35cc_5",
   "requests 2.20.1 py36_0",
   "ruamel_yaml 0.15.46 py36h1de35cc_0",
   "setuptools 40.6.2 py36_0",
   "six 1.11.0 py36_1",
   "sqlite 3.25.3 ha441bb4_0",
   "tk 8.6.8 ha441bb4_0",
   "tqdm 4.28.1 py36h28b3542_0",
   "traitlets 4.3.2 py36h65bd3ce_0",
   "urllib3 1.23 py36_0",
   "wheel 0.32.3 py36_0",
   "xz 5.2.4 h1de35cc_4",
   "yaml 0.1.7 hc338f04_2",
   "zlib 1.2.11 hf3cbc9b_2",
   "zstd 1.3.7 h5bba6e5_0"
  ],
  "summary": "Airflow is a platform to programmatically author, schedule and monitor workflows",
  "tags": []
 },
 "conda_build_config": {
  "CONDA_BUILD_SYSROOT": "/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.9.sdk",
  "MACOSX_DEPLOYMENT_TARGET": "10.9",
  "build_number_decrement": "0",
  "c_compiler": "clang",
  "channel_sources": "conda-forge,defaults",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cxx_compiler": "clangxx",
  "docker_image": "condaforge/linux-anvil",
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": "python",
  "lua": "5",
  "macos_machine": "x86_64-apple-darwin13.4.0",
  "macos_min_version": "10.9",
  "numpy": "1.11",
  "perl": "5.26.0",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x.x",
    "min_pin": "x.x.x"
   }
  },
  "python": "2.7",
  "r_base": "3.5",
  "target_platform": "osx-64"
 },
 "files": [],
 "index": {
  "arch": "x86_64",
  "build": "0",
  "build_number": 0,
  "depends": [
   "airflow >=1.10.1,<1.10.2.0a0",
   "pymongo >=3.6.0"
  ],
  "license": "Apache 2.0",
  "name": "airflow-with-mongo",
  "platform": "osx",
  "subdir": "osx-64",
  "timestamp": 1542872985128,
  "version": "1.10.1"
 },
 "metadata_version": 1,
 "name": "airflow-with-mongo",
 "raw_recipe": "# This file created by conda-build 3.16.3\n# ------------------------------------------------\n\npackage:\n    name: airflow-with-mongo\n    version: 1.10.1\nsource:\n    fn: airflow-1.10.1.tar.gz\n    sha256: 9fe8def33ba50e9f6c3f53ef25dbf986ebf6ed857409a338208c29b08de200e4\n    url: https://github.com/apache/incubator-airflow/archive/1.10.1.tar.gz\nbuild:\n    noarch: false\n    number: '0'\n    string: '0'\nrequirements:\n    run:\n        - airflow >=1.10.1,<1.10.2.0a0\n        - pymongo >=3.6.0\nabout:\n    description: 'Use airflow to author workflows as directed acyclic graphs (DAGs)\n\n        of tasks. The airflow scheduler executes your tasks on an array of\n\n        workers while following the specified dependencies. Rich command\n\n        line utilities make performing complex surgeries on DAGs a snap.\n\n        The rich user interface makes it easy to visualize pipelines\n\n        running in production, monitor progress, and troubleshoot issues\n\n        when needed.\n\n\n        When workflows are defined as code, they become more maintainable,\n\n        versionable, testable, and collaborative.\n\n        '\n    dev_url: https://github.com/apache/incubating-airflow\n    doc_url: http://pythonhosted.org/airflow/profiling.html\n    home: http://airflow.apache.org\n    license: Apache 2.0\n    license_file: LICENSE\n    summary: Airflow is a platform to programmatically author, schedule and monitor\n        workflows\nextra:\n    copy_test_source_files: true\n    final: true\n    recipe-maintainers:\n        - halldc\n        - sodre\n",
 "rendered_recipe": {
  "about": {
   "description": "Use airflow to author workflows as directed acyclic graphs (DAGs)\nof tasks. The airflow scheduler executes your tasks on an array of\nworkers while following the specified dependencies. Rich command\nline utilities make performing complex surgeries on DAGs a snap.\nThe rich user interface makes it easy to visualize pipelines\nrunning in production, monitor progress, and troubleshoot issues\nwhen needed.\n\nWhen workflows are defined as code, they become more maintainable,\nversionable, testable, and collaborative.\n",
   "dev_url": "https://github.com/apache/incubating-airflow",
   "doc_url": "http://pythonhosted.org/airflow/profiling.html",
   "home": "http://airflow.apache.org",
   "license": "Apache 2.0",
   "license_file": "LICENSE",
   "summary": "Airflow is a platform to programmatically author, schedule and monitor workflows"
  },
  "build": {
   "noarch": false,
   "number": "0",
   "string": "0"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "halldc",
    "sodre"
   ]
  },
  "package": {
   "name": "airflow-with-mongo",
   "version": "1.10.1"
  },
  "requirements": {
   "run": [
    "airflow >=1.10.1,<1.10.2.0a0",
    "pymongo >=3.6.0"
   ]
  },
  "source": {
   "fn": "airflow-1.10.1.tar.gz",
   "sha256": "9fe8def33ba50e9f6c3f53ef25dbf986ebf6ed857409a338208c29b08de200e4",
   "url": "https://github.com/apache/incubator-airflow/archive/1.10.1.tar.gz"
  }
 },
 "version": "1.10.1"
}