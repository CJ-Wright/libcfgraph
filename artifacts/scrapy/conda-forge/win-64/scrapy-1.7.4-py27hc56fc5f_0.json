{
 "about": {
  "channels": [
   "conda-forge",
   "defaults"
  ],
  "conda_build_version": "3.18.10",
  "conda_private": false,
  "conda_version": "4.7.12",
  "description": "Scrapy is an open source and collaborative framework for extracting the\ndata you need from websites in a fast, simple, yet extensible way.\n",
  "dev_url": "https://github.com/scrapy/scrapy",
  "doc_url": "https://docs.scrapy.org",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "rmax",
    "redapple",
    "kmike",
    "Gallaecio",
    "wRAR",
    "dangra"
   ]
  },
  "home": "https://scrapy.org/",
  "identifiers": [],
  "keywords": [],
  "license": "BSD 3-Clauses",
  "license_file": "LICENSE",
  "root_pkgs": [
   "anaconda-client 1.7.2 py_0",
   "asn1crypto 1.2.0 py36_0",
   "attrs 19.3.0 py_0",
   "beautifulsoup4 4.8.1 py36_0",
   "bzip2 1.0.8 hfa6e2cd_1",
   "ca-certificates 2019.9.11 hecc5488_0",
   "certifi 2019.9.11 py36_0",
   "cffi 1.13.0 py36hb32ad35_0",
   "chardet 3.0.4 py36_1003",
   "click 7.0 py_0",
   "clyent 1.2.2 py_1",
   "conda 4.7.12 py36_0",
   "conda-build 3.18.10 py36_0",
   "conda-env 2.6.0 1",
   "conda-forge-ci-setup 2.5.3 py36_0",
   "conda-package-handling 1.6.0 py36h2fa13f4_0",
   "console_shortcut 0.1.1 3",
   "cryptography 2.7 py36hb32ad35_0",
   "decorator 4.4.0 py_0",
   "filelock 3.0.10 py_0",
   "glob2 0.7 py_0",
   "idna 2.8 py36_1000",
   "importlib_metadata 0.23 py36_0",
   "ipython_genutils 0.2.0 py_1",
   "jinja2 2.10.3 py_0",
   "jsonschema 3.1.1 py36_0",
   "jupyter_core 4.5.0 py_0",
   "libarchive 3.4.0 h8ecf108_1",
   "libiconv 1.15 hfa6e2cd_1005",
   "liblief 0.9.0 ha925a31_2",
   "libxml2 2.9.9 h9ce36c8_5",
   "lz4-c 1.8.3 he025d50_1001",
   "lzo 2.10 hfa6e2cd_1000",
   "m2w64-gcc-libgfortran 5.3.0 6",
   "m2w64-gcc-libs 5.3.0 7",
   "m2w64-gcc-libs-core 5.3.0 7",
   "m2w64-gmp 6.1.0 2",
   "m2w64-libwinpthread-git 5.0.0.4634.697f757 2",
   "markupsafe 1.1.1 py36hfa6e2cd_0",
   "menuinst 1.4.16 py36_0",
   "more-itertools 7.2.0 py_0",
   "msys2-conda-epoch 20160418 1",
   "nbformat 4.4.0 py_1",
   "openssl 1.1.1c hfa6e2cd_0",
   "pip 19.3.1 py36_0",
   "pkginfo 1.5.0.1 py_0",
   "powershell_shortcut 0.0.1 2",
   "psutil 5.6.3 py36hfa6e2cd_0",
   "py-lief 0.9.0 py36ha925a31_2",
   "pycosat 0.6.3 py36hfa6e2cd_1001",
   "pycparser 2.19 py36_1",
   "pyopenssl 19.0.0 py36_0",
   "pyrsistent 0.15.4 py36hfa6e2cd_0",
   "pysocks 1.7.1 py36_0",
   "python 3.6.7 he025d50_1005",
   "python-dateutil 2.8.0 py_0",
   "python-libarchive-c 2.8 py36_1004",
   "pytz 2019.3 py_0",
   "pywin32 224 py36hfa6e2cd_1000",
   "pyyaml 5.1.2 py36hfa6e2cd_0",
   "requests 2.22.0 py36_1",
   "ripgrep 11.0.2 h301d43c_3",
   "ruamel_yaml 0.15.71 py36hfa6e2cd_1000",
   "setuptools 41.4.0 py36_0",
   "six 1.12.0 py36_1000",
   "soupsieve 1.9.4 py36_0",
   "sqlite 3.27.2 he774522_0",
   "tqdm 4.36.1 py_0",
   "traitlets 4.3.3 py36_0",
   "urllib3 1.25.6 py36_0",
   "vc 14.1 h0510ff6_4",
   "vs2008_express_vc_python_patch 1.0.0 0",
   "vs2015_runtime 14.15.26706 h3a45250_0",
   "wheel 0.33.6 py36_0",
   "wincertstore 0.2 py36_1002",
   "win_inet_pton 1.1.0 py36_0",
   "xz 5.2.4 h2fa13f4_1001",
   "yaml 0.1.7 hc54c509_2",
   "zipp 0.6.0 py_0",
   "zlib 1.2.11 h2fa13f4_1006",
   "zstd 1.4.3 hd8a0e53_0"
  ],
  "summary": "A high-level Python Screen Scraping framework",
  "tags": []
 },
 "conda_build_config": {
  "CI": "azure",
  "c_compiler": "vs2008",
  "channel_sources": "conda-forge,defaults",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cxx_compiler": "vs2008",
  "extend_keys": [
   "pin_run_as_build",
   "ignore_build_only_deps",
   "ignore_version",
   "extend_keys"
  ],
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": [
   "numpy",
   "python"
  ],
  "lua": "5",
  "numpy": "1.11",
  "perl": "5.26.0",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   }
  },
  "python": "2.7",
  "r_base": "3.4",
  "target_platform": "win-64",
  "vc": "14",
  "zip_keys": [
   [
    "python",
    "c_compiler",
    "cxx_compiler"
   ]
  ]
 },
 "files": [
  "Lib/site-packages/Scrapy-1.7.4.dist-info/AUTHORS",
  "Lib/site-packages/Scrapy-1.7.4.dist-info/INSTALLER",
  "Lib/site-packages/Scrapy-1.7.4.dist-info/LICENSE",
  "Lib/site-packages/Scrapy-1.7.4.dist-info/METADATA",
  "Lib/site-packages/Scrapy-1.7.4.dist-info/RECORD",
  "Lib/site-packages/Scrapy-1.7.4.dist-info/WHEEL",
  "Lib/site-packages/scrapy/VERSION",
  "Lib/site-packages/scrapy/__init__.py",
  "Lib/site-packages/scrapy/__main__.py",
  "Lib/site-packages/scrapy/_monkeypatches.py",
  "Lib/site-packages/scrapy/cmdline.py",
  "Lib/site-packages/scrapy/commands/__init__.py",
  "Lib/site-packages/scrapy/commands/bench.py",
  "Lib/site-packages/scrapy/commands/check.py",
  "Lib/site-packages/scrapy/commands/crawl.py",
  "Lib/site-packages/scrapy/commands/edit.py",
  "Lib/site-packages/scrapy/commands/fetch.py",
  "Lib/site-packages/scrapy/commands/genspider.py",
  "Lib/site-packages/scrapy/commands/list.py",
  "Lib/site-packages/scrapy/commands/parse.py",
  "Lib/site-packages/scrapy/commands/runspider.py",
  "Lib/site-packages/scrapy/commands/settings.py",
  "Lib/site-packages/scrapy/commands/shell.py",
  "Lib/site-packages/scrapy/commands/startproject.py",
  "Lib/site-packages/scrapy/commands/version.py",
  "Lib/site-packages/scrapy/commands/view.py",
  "Lib/site-packages/scrapy/contracts/__init__.py",
  "Lib/site-packages/scrapy/contracts/default.py",
  "Lib/site-packages/scrapy/core/__init__.py",
  "Lib/site-packages/scrapy/core/downloader/__init__.py",
  "Lib/site-packages/scrapy/core/downloader/contextfactory.py",
  "Lib/site-packages/scrapy/core/downloader/handlers/__init__.py",
  "Lib/site-packages/scrapy/core/downloader/handlers/datauri.py",
  "Lib/site-packages/scrapy/core/downloader/handlers/file.py",
  "Lib/site-packages/scrapy/core/downloader/handlers/ftp.py",
  "Lib/site-packages/scrapy/core/downloader/handlers/http.py",
  "Lib/site-packages/scrapy/core/downloader/handlers/http10.py",
  "Lib/site-packages/scrapy/core/downloader/handlers/http11.py",
  "Lib/site-packages/scrapy/core/downloader/handlers/s3.py",
  "Lib/site-packages/scrapy/core/downloader/middleware.py",
  "Lib/site-packages/scrapy/core/downloader/tls.py",
  "Lib/site-packages/scrapy/core/downloader/webclient.py",
  "Lib/site-packages/scrapy/core/engine.py",
  "Lib/site-packages/scrapy/core/scheduler.py",
  "Lib/site-packages/scrapy/core/scraper.py",
  "Lib/site-packages/scrapy/core/spidermw.py",
  "Lib/site-packages/scrapy/crawler.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/__init__.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/ajaxcrawl.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/chunked.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/cookies.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/decompression.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/defaultheaders.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/downloadtimeout.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/httpauth.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/httpcache.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/httpcompression.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/httpproxy.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/redirect.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/retry.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/robotstxt.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/stats.py",
  "Lib/site-packages/scrapy/downloadermiddlewares/useragent.py",
  "Lib/site-packages/scrapy/dupefilters.py",
  "Lib/site-packages/scrapy/exceptions.py",
  "Lib/site-packages/scrapy/exporters.py",
  "Lib/site-packages/scrapy/extension.py",
  "Lib/site-packages/scrapy/extensions/__init__.py",
  "Lib/site-packages/scrapy/extensions/closespider.py",
  "Lib/site-packages/scrapy/extensions/corestats.py",
  "Lib/site-packages/scrapy/extensions/debug.py",
  "Lib/site-packages/scrapy/extensions/feedexport.py",
  "Lib/site-packages/scrapy/extensions/httpcache.py",
  "Lib/site-packages/scrapy/extensions/logstats.py",
  "Lib/site-packages/scrapy/extensions/memdebug.py",
  "Lib/site-packages/scrapy/extensions/memusage.py",
  "Lib/site-packages/scrapy/extensions/spiderstate.py",
  "Lib/site-packages/scrapy/extensions/statsmailer.py",
  "Lib/site-packages/scrapy/extensions/telnet.py",
  "Lib/site-packages/scrapy/extensions/throttle.py",
  "Lib/site-packages/scrapy/http/__init__.py",
  "Lib/site-packages/scrapy/http/common.py",
  "Lib/site-packages/scrapy/http/cookies.py",
  "Lib/site-packages/scrapy/http/headers.py",
  "Lib/site-packages/scrapy/http/request/__init__.py",
  "Lib/site-packages/scrapy/http/request/form.py",
  "Lib/site-packages/scrapy/http/request/json_request.py",
  "Lib/site-packages/scrapy/http/request/rpc.py",
  "Lib/site-packages/scrapy/http/response/__init__.py",
  "Lib/site-packages/scrapy/http/response/html.py",
  "Lib/site-packages/scrapy/http/response/text.py",
  "Lib/site-packages/scrapy/http/response/xml.py",
  "Lib/site-packages/scrapy/interfaces.py",
  "Lib/site-packages/scrapy/item.py",
  "Lib/site-packages/scrapy/link.py",
  "Lib/site-packages/scrapy/linkextractors/__init__.py",
  "Lib/site-packages/scrapy/linkextractors/htmlparser.py",
  "Lib/site-packages/scrapy/linkextractors/lxmlhtml.py",
  "Lib/site-packages/scrapy/linkextractors/regex.py",
  "Lib/site-packages/scrapy/linkextractors/sgml.py",
  "Lib/site-packages/scrapy/loader/__init__.py",
  "Lib/site-packages/scrapy/loader/common.py",
  "Lib/site-packages/scrapy/loader/processors.py",
  "Lib/site-packages/scrapy/logformatter.py",
  "Lib/site-packages/scrapy/mail.py",
  "Lib/site-packages/scrapy/middleware.py",
  "Lib/site-packages/scrapy/mime.types",
  "Lib/site-packages/scrapy/pipelines/__init__.py",
  "Lib/site-packages/scrapy/pipelines/files.py",
  "Lib/site-packages/scrapy/pipelines/images.py",
  "Lib/site-packages/scrapy/pipelines/media.py",
  "Lib/site-packages/scrapy/pqueues.py",
  "Lib/site-packages/scrapy/resolver.py",
  "Lib/site-packages/scrapy/responsetypes.py",
  "Lib/site-packages/scrapy/selector/__init__.py",
  "Lib/site-packages/scrapy/selector/unified.py",
  "Lib/site-packages/scrapy/settings/__init__.py",
  "Lib/site-packages/scrapy/settings/default_settings.py",
  "Lib/site-packages/scrapy/settings/deprecated.py",
  "Lib/site-packages/scrapy/shell.py",
  "Lib/site-packages/scrapy/signalmanager.py",
  "Lib/site-packages/scrapy/signals.py",
  "Lib/site-packages/scrapy/spiderloader.py",
  "Lib/site-packages/scrapy/spidermiddlewares/__init__.py",
  "Lib/site-packages/scrapy/spidermiddlewares/depth.py",
  "Lib/site-packages/scrapy/spidermiddlewares/httperror.py",
  "Lib/site-packages/scrapy/spidermiddlewares/offsite.py",
  "Lib/site-packages/scrapy/spidermiddlewares/referer.py",
  "Lib/site-packages/scrapy/spidermiddlewares/urllength.py",
  "Lib/site-packages/scrapy/spiders/__init__.py",
  "Lib/site-packages/scrapy/spiders/crawl.py",
  "Lib/site-packages/scrapy/spiders/feed.py",
  "Lib/site-packages/scrapy/spiders/init.py",
  "Lib/site-packages/scrapy/spiders/sitemap.py",
  "Lib/site-packages/scrapy/squeues.py",
  "Lib/site-packages/scrapy/statscollectors.py",
  "Lib/site-packages/scrapy/templates/project/module/__init__.py",
  "Lib/site-packages/scrapy/templates/project/module/items.py.tmpl",
  "Lib/site-packages/scrapy/templates/project/module/middlewares.py.tmpl",
  "Lib/site-packages/scrapy/templates/project/module/pipelines.py.tmpl",
  "Lib/site-packages/scrapy/templates/project/module/settings.py.tmpl",
  "Lib/site-packages/scrapy/templates/project/module/spiders/__init__.py",
  "Lib/site-packages/scrapy/templates/project/scrapy.cfg",
  "Lib/site-packages/scrapy/templates/spiders/basic.tmpl",
  "Lib/site-packages/scrapy/templates/spiders/crawl.tmpl",
  "Lib/site-packages/scrapy/templates/spiders/csvfeed.tmpl",
  "Lib/site-packages/scrapy/templates/spiders/xmlfeed.tmpl",
  "Lib/site-packages/scrapy/utils/__init__.py",
  "Lib/site-packages/scrapy/utils/benchserver.py",
  "Lib/site-packages/scrapy/utils/boto.py",
  "Lib/site-packages/scrapy/utils/conf.py",
  "Lib/site-packages/scrapy/utils/console.py",
  "Lib/site-packages/scrapy/utils/datatypes.py",
  "Lib/site-packages/scrapy/utils/decorators.py",
  "Lib/site-packages/scrapy/utils/defer.py",
  "Lib/site-packages/scrapy/utils/deprecate.py",
  "Lib/site-packages/scrapy/utils/display.py",
  "Lib/site-packages/scrapy/utils/engine.py",
  "Lib/site-packages/scrapy/utils/ftp.py",
  "Lib/site-packages/scrapy/utils/gz.py",
  "Lib/site-packages/scrapy/utils/http.py",
  "Lib/site-packages/scrapy/utils/httpobj.py",
  "Lib/site-packages/scrapy/utils/iterators.py",
  "Lib/site-packages/scrapy/utils/job.py",
  "Lib/site-packages/scrapy/utils/log.py",
  "Lib/site-packages/scrapy/utils/markup.py",
  "Lib/site-packages/scrapy/utils/misc.py",
  "Lib/site-packages/scrapy/utils/multipart.py",
  "Lib/site-packages/scrapy/utils/ossignal.py",
  "Lib/site-packages/scrapy/utils/project.py",
  "Lib/site-packages/scrapy/utils/python.py",
  "Lib/site-packages/scrapy/utils/reactor.py",
  "Lib/site-packages/scrapy/utils/reqser.py",
  "Lib/site-packages/scrapy/utils/request.py",
  "Lib/site-packages/scrapy/utils/response.py",
  "Lib/site-packages/scrapy/utils/serialize.py",
  "Lib/site-packages/scrapy/utils/signal.py",
  "Lib/site-packages/scrapy/utils/sitemap.py",
  "Lib/site-packages/scrapy/utils/spider.py",
  "Lib/site-packages/scrapy/utils/template.py",
  "Lib/site-packages/scrapy/utils/test.py",
  "Lib/site-packages/scrapy/utils/testproc.py",
  "Lib/site-packages/scrapy/utils/testsite.py",
  "Lib/site-packages/scrapy/utils/trackref.py",
  "Lib/site-packages/scrapy/utils/url.py",
  "Lib/site-packages/scrapy/utils/versions.py",
  "Lib/site-packages/scrapy/xlib/__init__.py",
  "Lib/site-packages/scrapy/xlib/pydispatch.py",
  "Lib/site-packages/scrapy/xlib/tx.py",
  "Scripts/scrapy.exe"
 ],
 "index": {
  "arch": "x86_64",
  "build": "py27hc56fc5f_0",
  "build_number": 0,
  "depends": [
   "cssselect >=0.9",
   "lxml",
   "parsel >=1.5.0",
   "pydispatcher >=2.0.5",
   "pyopenssl",
   "python >=2.7,<2.8.0a0",
   "pywin32",
   "queuelib",
   "service_identity",
   "setuptools",
   "six >=1.5.2",
   "twisted >=16.4.0",
   "w3lib >=1.17.0"
  ],
  "license": "BSD 3-Clauses",
  "name": "scrapy",
  "platform": "win",
  "subdir": "win-64",
  "timestamp": 1571659426936,
  "version": "1.7.4"
 },
 "metadata_version": 1,
 "name": "scrapy",
 "raw_recipe": "#\n# See the guidelines for updating this recipe for new releases:\n# https://github.com/scrapy/scrapy/wiki/Scrapy-release-procedure#conda-packages\n#\n{% set name = \"Scrapy\" %}\n{% set version = \"1.7.4\" %}\n{% set hash_type = \"sha256\" %}\n{% set hash_val = \"f0813d23a3f5659f403f469b11488ecd81e989e834205c4366cd231536496513\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  fn: {{ name }}-{{ version }}.tar.gz\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  {{ hash_type }}: {{ hash_val }}\n\nbuild:\n  script: \"{{ PYTHON }} -m pip install . --no-deps -vv\"\n  number: 0\n\n# The requirements below shall match the requirements from the target package\n# version (check setup.py for changes).\nrequirements:\n  host:\n    - python\n    - pip\n    - setuptools\n\n  run:\n    - python\n    - setuptools\n    - twisted >=13.1.0  # [not py34 and not win]\n    - twisted >=13.1.0,<=19.2.0  # [py34 and not win]\n    - twisted >=16.4.0  # [win]\n    - w3lib >=1.17.0\n    - queuelib\n    - lxml  # [not py34]\n    - lxml <=4.3.5  # [py34]\n    - pyopenssl\n    - cssselect >=0.9\n    - six >=1.5.2\n    - parsel >=1.5.0\n    - pydispatcher >=2.0.5\n    - service_identity\n    - pywin32  # [win]\n\ntest:\n  requires:\n    - {{ compiler('c') }}\n    - {{ compiler(\"cxx\") }}\n    - brotlipy  # [win]\n    - pip\n  source_files:\n    - conftest.py\n    - requirements-py2.txt\n    - requirements-py3.txt\n    - scrapy\n    - tests\n  commands:\n    - scrapy version  # [not win]\n    - sed -i '/brotlipy/d' tests/requirements-py2.txt  # [win]\n    - pip install setuptools-scm  # required by indirect dependency pytest-forked\n    - pip install -ctests/constraints.txt -rrequirements-py2.txt -rtests/requirements-py2.txt Pillow!=3.0.0 botocore google-cloud-storage  # [py27]\n    - pip install -ctests/constraints.txt -rrequirements-py3.txt -rtests/requirements-py3.txt Pillow  # [py3k]\n    - mv scrapy _scrapy\n    - rm tests/test_command_parse.py tests/test_command_shell.py tests/test_commands.py tests/test_crawler.py tests/test_downloader_handlers.py tests/test_exporters.py tests/test_feedexport.py tests/test_proxy_connect.py tests/test_utils_trackref.py  # [win]\n    - rm tests/test_command_parse.py tests/test_commands.py tests/test_crawler.py tests/test_downloader_handlers.py  # [osx]\n    - pytest _scrapy tests\n\nabout:\n  home: https://scrapy.org/\n  license: BSD 3-Clauses\n  license_file: LICENSE\n  summary: A high-level Python Screen Scraping framework\n  description: |\n    Scrapy is an open source and collaborative framework for extracting the\n    data you need from websites in a fast, simple, yet extensible way.\n  doc_url: https://docs.scrapy.org\n  dev_url: https://github.com/scrapy/scrapy\n\nextra:\n  recipe-maintainers:\n    - rmax\n    - redapple\n    - kmike\n    - Gallaecio\n    - wRAR\n    - dangra\n",
 "rendered_recipe": {
  "about": {
   "description": "Scrapy is an open source and collaborative framework for extracting the\ndata you need from websites in a fast, simple, yet extensible way.\n",
   "dev_url": "https://github.com/scrapy/scrapy",
   "doc_url": "https://docs.scrapy.org",
   "home": "https://scrapy.org/",
   "license": "BSD 3-Clauses",
   "license_file": "LICENSE",
   "summary": "A high-level Python Screen Scraping framework"
  },
  "build": {
   "number": "0",
   "script": "D:\\bld\\scrapy_1571659193770\\_h_env\\python.exe -m pip install . --no-deps -vv",
   "string": "py27hc56fc5f_0"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "Gallaecio",
    "dangra",
    "kmike",
    "redapple",
    "rmax",
    "wRAR"
   ]
  },
  "package": {
   "name": "scrapy",
   "version": "1.7.4"
  },
  "requirements": {
   "host": [
    "certifi 2019.9.11 py27_0",
    "pip 19.3.1 py27_0",
    "python 2.7.15 h2880e7c_1009",
    "setuptools 41.4.0 py27_0",
    "vc 9 h7299396_1",
    "vs2008_runtime 9.0.30729.6161 0",
    "wheel 0.33.6 py27_0",
    "wincertstore 0.2 py27_1002"
   ],
   "run": [
    "cssselect >=0.9",
    "lxml",
    "parsel >=1.5.0",
    "pydispatcher >=2.0.5",
    "pyopenssl",
    "python >=2.7,<2.8.0a0",
    "pywin32",
    "queuelib",
    "service_identity",
    "setuptools",
    "six >=1.5.2",
    "twisted >=16.4.0",
    "w3lib >=1.17.0"
   ]
  },
  "source": {
   "fn": "Scrapy-1.7.4.tar.gz",
   "sha256": "f0813d23a3f5659f403f469b11488ecd81e989e834205c4366cd231536496513",
   "url": "https://pypi.io/packages/source/S/Scrapy/Scrapy-1.7.4.tar.gz"
  },
  "test": {
   "commands": [
    "sed -i '/brotlipy/d' tests/requirements-py2.txt",
    "pip install setuptools-scm",
    "pip install -ctests/constraints.txt -rrequirements-py2.txt -rtests/requirements-py2.txt Pillow!=3.0.0 botocore google-cloud-storage",
    "mv scrapy _scrapy",
    "rm tests/test_command_parse.py tests/test_command_shell.py tests/test_commands.py tests/test_crawler.py tests/test_downloader_handlers.py tests/test_exporters.py tests/test_feedexport.py tests/test_proxy_connect.py tests/test_utils_trackref.py",
    "pytest _scrapy tests"
   ],
   "requires": [
    "brotlipy",
    "pip",
    "vs2008_win-64"
   ],
   "source_files": [
    "conftest.py",
    "requirements-py2.txt",
    "requirements-py3.txt",
    "scrapy",
    "tests"
   ]
  }
 },
 "version": "1.7.4"
}