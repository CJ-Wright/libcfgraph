{
 "about": {
  "channels": [
   "conda-forge",
   "defaults"
  ],
  "conda_build_version": "3.17.5",
  "conda_private": false,
  "conda_version": "4.5.12",
  "description": "cw-eval is an evaluation suite for scoring entries in geospatial image\nanalysis competitions. It includes tools for calculating IoU scores,\nprecision, recall, F1 score, and scripts to score entire entries in either\ngeojson or csv formats.\n",
  "dev_url": "https://github.com/cosmiq/cw-eval",
  "doc_url": "http://cw-eval.readthedocs.io/",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "nrweir"
   ]
  },
  "home": "http://github.com/cosmiq/cw-eval",
  "identifiers": [],
  "keywords": [],
  "license": "Apache-2.0",
  "license_family": "Apache",
  "license_file": "/home/conda/recipe_root/LICENSE.txt",
  "root_pkgs": [
   "filelock 3.0.10 py_0",
   "conda-build 3.17.5 py36_0",
   "libstdcxx-ng 7.2.0 hdf63c60_3",
   "bzip2 1.0.6 h470a237_2",
   "beautifulsoup4 4.6.3 py36_1000",
   "sqlite 3.26.0 hb1c47c0_0",
   "conda 4.5.12 py36_1000",
   "asn1crypto 0.24.0 py36_1003",
   "python-libarchive-c 2.8 py36_1004",
   "libssh2 1.8.0 h5b517e9_3",
   "libedit 3.1.20170329 haf1bffa_1",
   "krb5 1.16.2 hbb41f41_0",
   "readline 7.0 haf1bffa_1",
   "anaconda-client 1.7.1 py_0",
   "xz 5.2.4 h470a237_1",
   "pycosat 0.6.3 py36h470a237_1",
   "libiconv 1.15 h470a237_3",
   "yaml 0.1.7 h470a237_1",
   "curl 7.63.0 h74213dd_0",
   "markupsafe 1.1.0 py36h470a237_0",
   "pycparser 2.19 py_0",
   "attrs 18.2.0 py_0",
   "pyrsistent 0.14.8 py36h470a237_0",
   "zlib 1.2.11 h470a237_3",
   "ca-certificates 2018.11.29 ha4d7672_0",
   "tini 0.18.0 h470a237_1",
   "pyyaml 3.13 py36h470a237_1",
   "setuptools 40.6.3 py36_0",
   "six 1.12.0 py36_1000",
   "pytz 2018.7 py_0",
   "cryptography-vectors 2.3.1 py36_1000",
   "pysocks 1.6.8 py36_1002",
   "requests 2.21.0 py36_1000",
   "decorator 4.3.0 py_0",
   "glob2 0.6 py_0",
   "psutil 5.4.8 py36h470a237_0",
   "python-dateutil 2.7.5 py_0",
   "jinja2 2.10 py_1",
   "cryptography 2.3.1 py36hdffb7b8_0",
   "nbformat 4.4.0 py_1",
   "chardet 3.0.4 py36_1003",
   "traitlets 4.3.2 py36_1000",
   "conda-env 2.6.0 1",
   "wheel 0.32.3 py36_0",
   "pkginfo 1.4.2 py_1",
   "patchelf 0.9 hfc679d8_2",
   "tk 8.6.9 ha92aebf_0",
   "certifi 2018.11.29 py36_1000",
   "pip 18.1 py36_1000",
   "libcurl 7.63.0 hbdb9355_0",
   "perl 5.26.2 h470a237_0",
   "ncurses 6.1 hfc679d8_2",
   "git 2.20.1 pl526hbb17d3c_0",
   "ipython_genutils 0.2.0 py_1",
   "ruamel_yaml 0.15.71 py36h470a237_0",
   "libffi 3.2.1 hfc679d8_5",
   "jupyter_core 4.4.0 py_0",
   "tqdm 4.28.1 py_0",
   "cffi 1.11.5 py36h5e8e0c9_1",
   "urllib3 1.24.1 py36_1000",
   "pyopenssl 18.0.0 py36_1000",
   "py-lief 0.9.0 py36h1532aa0_0",
   "expat 2.2.5 hfc679d8_2",
   "liblief 0.9.0 h1532aa0_0",
   "jsonschema 3.0.0a3 py36_1000",
   "idna 2.8 py36_1000",
   "gettext 0.19.8.1 h5e8e0c9_1",
   "python 3.6.7 h5001a0f_1",
   "gosu 1.10 h81701ea_1001",
   "clyent 1.2.2 py_1",
   "libgcc-ng 7.2.0 hdf63c60_3",
   "libarchive 3.3.3 h823be47_0",
   "conda-forge-ci-setup 2.1.1 py36_0",
   "click 7.0 py_0",
   "openssl 1.0.2p h470a237_2"
  ],
  "summary": "Evaluation metrics for Geospatial Machine Learning Challenges",
  "tags": []
 },
 "conda_build_config": {
  "build_number_decrement": "1000",
  "c_compiler": "toolchain_c",
  "channel_sources": "conda-forge,defaults",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cxx_compiler": "gxx",
  "docker_image": "condaforge/linux-anvil",
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": "python",
  "lua": "5",
  "numpy": "1.11",
  "perl": "5.26.0",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x.x",
    "min_pin": "x.x.x"
   }
  },
  "python": "3.6",
  "r_base": "3.5",
  "target_platform": "linux-64",
  "zip_keys": [
   [
    "c_compiler",
    "channel_sources",
    "channel_targets",
    "docker_image",
    "build_number_decrement"
   ]
  ]
 },
 "files": [
  "bin/spacenet_eval",
  "lib/python3.6/site-packages/cw_eval-1.0.0.dist-info/INSTALLER",
  "lib/python3.6/site-packages/cw_eval-1.0.0.dist-info/METADATA",
  "lib/python3.6/site-packages/cw_eval-1.0.0.dist-info/RECORD",
  "lib/python3.6/site-packages/cw_eval-1.0.0.dist-info/WHEEL",
  "lib/python3.6/site-packages/cw_eval/__init__.py",
  "lib/python3.6/site-packages/cw_eval/baseeval.py",
  "lib/python3.6/site-packages/cw_eval/challenge_eval/__init__.py",
  "lib/python3.6/site-packages/cw_eval/challenge_eval/off_nadir_dataset.py",
  "lib/python3.6/site-packages/cw_eval/challenge_eval/spacenet_eval.py",
  "lib/python3.6/site-packages/cw_eval/data/__init__.py",
  "lib/python3.6/site-packages/cw_eval/data/competition_test_results.csv",
  "lib/python3.6/site-packages/cw_eval/data/competition_test_results_full.csv",
  "lib/python3.6/site-packages/cw_eval/data/empty.geojson",
  "lib/python3.6/site-packages/cw_eval/data/gt.geojson",
  "lib/python3.6/site-packages/cw_eval/data/overlap_test.geojson",
  "lib/python3.6/site-packages/cw_eval/data/pred.geojson",
  "lib/python3.6/site-packages/cw_eval/data/sample_preds.csv",
  "lib/python3.6/site-packages/cw_eval/data/sample_preds_competition.csv",
  "lib/python3.6/site-packages/cw_eval/data/sample_truth.csv",
  "lib/python3.6/site-packages/cw_eval/data/sample_truth_competition.csv",
  "lib/python3.6/site-packages/cw_eval/data/test_results.csv",
  "lib/python3.6/site-packages/cw_eval/data/test_results_full.csv",
  "lib/python3.6/site-packages/cw_eval/evalfunctions.py"
 ],
 "index": {
  "arch": "x86_64",
  "build": "py36h470a237_0",
  "build_number": 0,
  "depends": [
   "geopandas",
   "libgcc-ng >=4.9",
   "pandas",
   "python >=3.6,<3.7.0a0",
   "rtree",
   "shapely",
   "tqdm"
  ],
  "license": "Apache-2.0",
  "license_family": "Apache",
  "name": "cw-eval",
  "platform": "linux",
  "subdir": "linux-64",
  "timestamp": 1546714404280,
  "version": "1.0.0"
 },
 "metadata_version": 1,
 "name": "cw-eval",
 "raw_recipe": "{% set name = \"cw-eval\" %}\n{% set version = \"1.0.0\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name|replace(\"-\",\"_\") }}-{{ version }}.tar.gz\n  sha256: 786da1252f274b84a326532569337d2fbb872aaad1132b88c72b8de473b9ddf3\n\n\nbuild:\n  number: 1000\n  script: \"{{ PYTHON }} -m pip install . --no-deps -vv\"\n\nrequirements:\n  build:\n    - {{ compiler('c') }}\n  host:\n    - python\n    - pip\n  run:\n    - python\n    - rtree\n    - shapely\n    - pandas\n    - geopandas\n    - tqdm\n\ntest:\n  imports:\n    cw_eval\n\nabout:\n  home: http://github.com/cosmiq/cw-eval\n  license: Apache-2.0\n  license_family: Apache\n  license_file: '{{ environ[\"RECIPE_DIR\"] }}/LICENSE.txt'\n  summary: 'Evaluation metrics for Geospatial Machine Learning Challenges'\n\n  description: |\n    cw-eval is an evaluation suite for scoring entries in geospatial image\n    analysis competitions. It includes tools for calculating IoU scores,\n    precision, recall, F1 score, and scripts to score entire entries in either\n    geojson or csv formats.\n  doc_url: http://cw-eval.readthedocs.io/\n  dev_url: https://github.com/cosmiq/cw-eval\n\nextra:\n  recipe-maintainers:\n    - nrweir\n",
 "rendered_recipe": {
  "about": {
   "description": "cw-eval is an evaluation suite for scoring entries in geospatial image\nanalysis competitions. It includes tools for calculating IoU scores,\nprecision, recall, F1 score, and scripts to score entire entries in either\ngeojson or csv formats.\n",
   "dev_url": "https://github.com/cosmiq/cw-eval",
   "doc_url": "http://cw-eval.readthedocs.io/",
   "home": "http://github.com/cosmiq/cw-eval",
   "license": "Apache-2.0",
   "license_family": "Apache",
   "license_file": "/home/conda/recipe_root/LICENSE.txt",
   "summary": "Evaluation metrics for Geospatial Machine Learning Challenges"
  },
  "build": {
   "number": "0",
   "script": "/home/conda/feedstock_root/build_artifacts/cw-eval_1546714253129/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . --no-deps -vv",
   "string": "py36h470a237_0"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "nrweir"
   ]
  },
  "package": {
   "name": "cw-eval",
   "version": "1.0.0"
  },
  "requirements": {
   "build": [
    "toolchain 2.4.0 0",
    "toolchain_c_linux-64 2.4.0 0"
   ],
   "host": [
    "ca-certificates 2018.11.29 ha4d7672_0",
    "certifi 2018.11.29 py36_1000",
    "libffi 3.2.1 hfc679d8_5",
    "libgcc-ng 7.2.0 hdf63c60_3",
    "libstdcxx-ng 7.2.0 hdf63c60_3",
    "ncurses 6.1 hfc679d8_2",
    "openssl 1.0.2p h470a237_2",
    "pip 18.1 py36_1000",
    "python 3.6.7 h5001a0f_1",
    "readline 7.0 haf1bffa_1",
    "setuptools 40.6.3 py36_0",
    "sqlite 3.26.0 hb1c47c0_0",
    "tk 8.6.9 ha92aebf_0",
    "wheel 0.32.3 py36_0",
    "xz 5.2.4 h470a237_1",
    "zlib 1.2.11 h470a237_3"
   ],
   "run": [
    "geopandas",
    "libgcc-ng >=4.9",
    "pandas",
    "python >=3.6,<3.7.0a0",
    "rtree",
    "shapely",
    "tqdm"
   ]
  },
  "source": {
   "sha256": "786da1252f274b84a326532569337d2fbb872aaad1132b88c72b8de473b9ddf3",
   "url": "https://pypi.io/packages/source/c/cw-eval/cw_eval-1.0.0.tar.gz"
  },
  "test": {
   "imports": "cw_eval"
  }
 },
 "version": "1.0.0"
}