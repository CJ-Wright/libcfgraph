{
 "about": {
  "channels": [
   "conda-forge",
   "defaults"
  ],
  "conda_build_version": "3.18.11",
  "conda_private": false,
  "conda_version": "4.7.12",
  "description": "cw-eval is an evaluation suite for scoring entries in geospatial image\nanalysis competitions. It includes tools for calculating IoU scores,\nprecision, recall, F1 score, and scripts to score entire entries in either\ngeojson or csv formats.\n",
  "dev_url": "https://github.com/cosmiq/cw-eval",
  "doc_url": "http://cw-eval.readthedocs.io/",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "nrweir"
   ]
  },
  "home": "http://github.com/cosmiq/cw-eval",
  "identifiers": [],
  "keywords": [],
  "license": "Apache-2.0",
  "license_family": "Apache",
  "license_file": "/Users/runner/runners/2.160.1/work/1/s/recipe/LICENSE.txt",
  "root_pkgs": [
   "anaconda-client 1.7.2 py_0",
   "attrs 19.3.0 py_0",
   "beautifulsoup4 4.8.1 py37_0",
   "bzip2 1.0.8 h01d97ff_1",
   "ca-certificates 2019.9.11 hecc5488_0",
   "certifi 2019.9.11 py37_0",
   "cffi 1.13.2 py37h33e799b_0",
   "chardet 3.0.4 py37_1003",
   "click 7.0 py_0",
   "clyent 1.2.2 py_1",
   "conda 4.7.12 py37_0",
   "conda-build 3.18.11 py37_0",
   "conda-env 2.6.0 1",
   "conda-forge-ci-setup 2.5.3 py37_0",
   "conda-package-handling 1.6.0 py37h0b31af3_1",
   "cryptography 2.8 py37hafa8578_0",
   "decorator 4.4.1 py_0",
   "filelock 3.0.10 py_0",
   "glob2 0.7 py_0",
   "icu 64.2 h6de7cb9_1",
   "idna 2.8 py37_1000",
   "importlib_metadata 0.23 py37_0",
   "ipython_genutils 0.2.0 py_1",
   "jinja2 2.10.3 py_0",
   "jq 1.6 h1de35cc_1000",
   "jsonschema 3.2.0 py37_0",
   "jupyter_core 4.6.1 py37_0",
   "libarchive 3.4.0 h8912c15_2",
   "libcxx 9.0.0 h89e68fa_1",
   "libffi 3.2.1 h6de7cb9_1006",
   "libiconv 1.15 h01d97ff_1005",
   "liblief 0.9.0 h2a1bed3_1",
   "libxml2 2.9.10 h53d96d6_0",
   "lz4-c 1.8.3 h6de7cb9_1001",
   "lzo 2.10 h1de35cc_1000",
   "markupsafe 1.1.1 py37h0b31af3_0",
   "more-itertools 7.2.0 py_0",
   "nbformat 4.4.0 py_1",
   "ncurses 6.1 h0a44026_1002",
   "oniguruma 6.9.3 h01d97ff_0",
   "openssl 1.1.1d h0b31af3_0",
   "pkginfo 1.5.0.1 py_0",
   "psutil 5.6.5 py37h0b31af3_0",
   "py-lief 0.9.0 py37h6d6d4d2_1",
   "pycosat 0.6.3 py37h0b31af3_1002",
   "pycparser 2.19 py37_1",
   "pyopenssl 19.0.0 py37_0",
   "pyrsistent 0.15.5 py37h0b31af3_0",
   "pysocks 1.7.1 py37_0",
   "python 3.7.3 h93065d6_1",
   "python-dateutil 2.8.1 py_0",
   "python-libarchive-c 2.9 py37_0",
   "python.app 1.2 py37h0b31af3_1201",
   "pytz 2019.3 py_0",
   "pyyaml 5.1.2 py37h0b31af3_0",
   "readline 8.0 hcfe32e1_0",
   "requests 2.22.0 py37_1",
   "ripgrep 11.0.2 h01d97ff_3",
   "ruamel_yaml 0.15.71 py37h1de35cc_1000",
   "setuptools 41.6.0 py37_1",
   "shyaml 0.6.1 py_0",
   "six 1.13.0 py37_0",
   "soupsieve 1.9.4 py37_0",
   "sqlite 3.30.1 h93121df_0",
   "tk 8.6.9 h2573ce8_1003",
   "tqdm 4.38.0 py_2",
   "traitlets 4.3.3 py37_0",
   "urllib3 1.25.7 py37_0",
   "xz 5.2.4 h1de35cc_1001",
   "yaml 0.1.7 h1de35cc_1001",
   "zipp 0.6.0 py_0",
   "zlib 1.2.11 h0b31af3_1006",
   "zstd 1.4.4 he7fca8b_1"
  ],
  "summary": "Evaluation metrics for Geospatial Machine Learning Challenges",
  "tags": []
 },
 "conda_build_config": {
  "CI": "azure",
  "CONDA_BUILD_SYSROOT": "/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.9.sdk",
  "MACOSX_DEPLOYMENT_TARGET": "10.9",
  "c_compiler": "clang",
  "c_compiler_version": "9",
  "channel_sources": "conda-forge,defaults",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cxx_compiler": "clangxx",
  "extend_keys": [
   "pin_run_as_build",
   "ignore_version",
   "extend_keys",
   "ignore_build_only_deps"
  ],
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": [
   "numpy",
   "python"
  ],
  "lua": "5",
  "macos_machine": "x86_64-apple-darwin13.4.0",
  "macos_min_version": "10.9",
  "numpy": "1.11",
  "perl": "5.26.0",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   }
  },
  "python": "3.8",
  "r_base": "3.5",
  "target_platform": "osx-64"
 },
 "files": [
  "bin/spacenet_eval",
  "lib/python3.8/site-packages/cw_eval-1.0.0.dist-info/INSTALLER",
  "lib/python3.8/site-packages/cw_eval-1.0.0.dist-info/METADATA",
  "lib/python3.8/site-packages/cw_eval-1.0.0.dist-info/RECORD",
  "lib/python3.8/site-packages/cw_eval-1.0.0.dist-info/WHEEL",
  "lib/python3.8/site-packages/cw_eval/__init__.py",
  "lib/python3.8/site-packages/cw_eval/baseeval.py",
  "lib/python3.8/site-packages/cw_eval/challenge_eval/__init__.py",
  "lib/python3.8/site-packages/cw_eval/challenge_eval/off_nadir_dataset.py",
  "lib/python3.8/site-packages/cw_eval/challenge_eval/spacenet_eval.py",
  "lib/python3.8/site-packages/cw_eval/data/__init__.py",
  "lib/python3.8/site-packages/cw_eval/data/competition_test_results.csv",
  "lib/python3.8/site-packages/cw_eval/data/competition_test_results_full.csv",
  "lib/python3.8/site-packages/cw_eval/data/empty.geojson",
  "lib/python3.8/site-packages/cw_eval/data/gt.geojson",
  "lib/python3.8/site-packages/cw_eval/data/overlap_test.geojson",
  "lib/python3.8/site-packages/cw_eval/data/pred.geojson",
  "lib/python3.8/site-packages/cw_eval/data/sample_preds.csv",
  "lib/python3.8/site-packages/cw_eval/data/sample_preds_competition.csv",
  "lib/python3.8/site-packages/cw_eval/data/sample_truth.csv",
  "lib/python3.8/site-packages/cw_eval/data/sample_truth_competition.csv",
  "lib/python3.8/site-packages/cw_eval/data/test_results.csv",
  "lib/python3.8/site-packages/cw_eval/data/test_results_full.csv",
  "lib/python3.8/site-packages/cw_eval/evalfunctions.py"
 ],
 "index": {
  "arch": "x86_64",
  "build": "py38h0b31af3_1000",
  "build_number": 1000,
  "depends": [
   "geopandas",
   "pandas",
   "python >=3.8,<3.9.0a0",
   "rtree",
   "shapely",
   "tqdm"
  ],
  "license": "Apache-2.0",
  "license_family": "Apache",
  "name": "cw-eval",
  "platform": "osx",
  "subdir": "osx-64",
  "timestamp": 1574256387261,
  "version": "1.0.0"
 },
 "metadata_version": 1,
 "name": "cw-eval",
 "raw_recipe": "{% set name = \"cw-eval\" %}\n{% set version = \"1.0.0\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name|replace(\"-\",\"_\") }}-{{ version }}.tar.gz\n  sha256: 786da1252f274b84a326532569337d2fbb872aaad1132b88c72b8de473b9ddf3\n\n\nbuild:\n  number: 1000\n  script: \"{{ PYTHON }} -m pip install . --no-deps -vv\"\n\nrequirements:\n  build:\n    - {{ compiler('c') }}\n  host:\n    - python\n    - pip\n  run:\n    - python\n    - rtree\n    - shapely\n    - pandas\n    - geopandas\n    - tqdm\n\ntest:\n  imports:\n    cw_eval\n\nabout:\n  home: http://github.com/cosmiq/cw-eval\n  license: Apache-2.0\n  license_family: Apache\n  license_file: '{{ environ[\"RECIPE_DIR\"] }}/LICENSE.txt'\n  summary: 'Evaluation metrics for Geospatial Machine Learning Challenges'\n\n  description: |\n    cw-eval is an evaluation suite for scoring entries in geospatial image\n    analysis competitions. It includes tools for calculating IoU scores,\n    precision, recall, F1 score, and scripts to score entire entries in either\n    geojson or csv formats.\n  doc_url: http://cw-eval.readthedocs.io/\n  dev_url: https://github.com/cosmiq/cw-eval\n\nextra:\n  recipe-maintainers:\n    - nrweir\n",
 "rendered_recipe": {
  "about": {
   "description": "cw-eval is an evaluation suite for scoring entries in geospatial image\nanalysis competitions. It includes tools for calculating IoU scores,\nprecision, recall, F1 score, and scripts to score entire entries in either\ngeojson or csv formats.\n",
   "dev_url": "https://github.com/cosmiq/cw-eval",
   "doc_url": "http://cw-eval.readthedocs.io/",
   "home": "http://github.com/cosmiq/cw-eval",
   "license": "Apache-2.0",
   "license_family": "Apache",
   "license_file": "/Users/runner/runners/2.160.1/work/1/s/recipe/LICENSE.txt",
   "summary": "Evaluation metrics for Geospatial Machine Learning Challenges"
  },
  "build": {
   "number": "1000",
   "script": "/usr/local/miniconda/conda-bld/cw-eval_1574256247134/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place/bin/python -m pip install . --no-deps -vv",
   "string": "py38h0b31af3_1000"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "nrweir"
   ]
  },
  "package": {
   "name": "cw-eval",
   "version": "1.0.0"
  },
  "requirements": {
   "build": [
    "cctools 921 h5ba7a2e_4",
    "clang 9.0.0 default_hf57f61e_4",
    "clang_osx-64 9.0.0 h22b1bf0_3",
    "clangxx 9.0.0 default_hf57f61e_4",
    "compiler-rt 9.0.0 h2b4a0d1_1",
    "ld64 409.12 h3c32e8a_4",
    "libcxx 9.0.0 h89e68fa_1",
    "libllvm9 9.0.0 h770b8ee_3",
    "tapi 1000.10.8 h770b8ee_3"
   ],
   "host": [
    "ca-certificates 2019.9.11 hecc5488_0",
    "certifi 2019.9.11 py38_0",
    "libcxx 9.0.0 h89e68fa_1",
    "libffi 3.2.1 h6de7cb9_1006",
    "ncurses 6.1 h0a44026_1002",
    "openssl 1.1.1d h0b31af3_0",
    "pip 19.3.1 py38_0",
    "python 3.8.0 hd366da7_3",
    "readline 8.0 hcfe32e1_0",
    "setuptools 41.6.0 py38_1",
    "sqlite 3.30.1 h93121df_0",
    "tk 8.6.9 h2573ce8_1003",
    "wheel 0.33.6 py38_0",
    "xz 5.2.4 h1de35cc_1001",
    "zlib 1.2.11 h0b31af3_1006"
   ],
   "run": [
    "geopandas",
    "pandas",
    "python >=3.8,<3.9.0a0",
    "rtree",
    "shapely",
    "tqdm"
   ]
  },
  "source": {
   "sha256": "786da1252f274b84a326532569337d2fbb872aaad1132b88c72b8de473b9ddf3",
   "url": "https://pypi.io/packages/source/c/cw-eval/cw_eval-1.0.0.tar.gz"
  },
  "test": {
   "imports": "cw_eval"
  }
 },
 "version": "1.0.0"
}